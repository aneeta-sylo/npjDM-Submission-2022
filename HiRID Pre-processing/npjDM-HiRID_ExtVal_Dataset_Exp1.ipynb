{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create HiRID External validation dataset (Experiment 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all necessary modules\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to HiRID database\n",
    "\n",
    "import psycopg2\n",
    "from psycopg2 import Error\n",
    "\n",
    "conn = psycopg2.connect(user=\"mimicuser\",\n",
    "                                  password=\"knowlabMIMIC\",\n",
    "                                  host=\"172.17.0.1\",\n",
    "                                  port=\"5433\",\n",
    "                                  database=\"HiRID\")\n",
    "\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Filtering for all instances with drug administration (Adrenaline/Noradrenaline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HiRID documentation contains the variableids for all drug variables:<br>\n",
    "https://hirid.intensivecare.ai/structure-of-the-published-data\n",
    "\n",
    "- **Adrenaline** (continuously administered): 1000649, 1000650\n",
    "- **Noradrenaline** (continuously administered): 1000656, 1000657"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to HiRID pharma_records table\n",
    "##filtering for only continuous Adrenaline/ Noradrenaline fields\n",
    "##pharmaids for continuous Adrenaline/Noradrenaline fields found in HiRID documentation - https://hirid.intensivecare.ai/structure-of-the-published-data\n",
    "\n",
    "#import all records from HiRID Pharma table containing continuous Adrenaline/Noradrenaline\n",
    "drugs_df = pd.read_sql_query(\"SELECT * FROM hirid.pharma_records \\\n",
    "                         WHERE pharmaid IN (1000649, 1000650, 1000656, 1000657) \\\n",
    "                         ORDER BY patientid, pharmaid, givenat\", conn)\n",
    "\n",
    "\n",
    "#categorise drugs_df 'givenat' column to closest 15min timepoint (needed for later analysis)\n",
    "drugs_df['timepoint'] = drugs_df['givenat'].dt.round('15min') \n",
    "\n",
    "print(drugs_df.shape)\n",
    "drugs_df.head()\n",
    "\n",
    "##1,458,539 records\n",
    "##NOTE: includes rows where given_dose=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter for records containing Adrenaline/Noradrenaline readings with non-zero values \n",
    "\n",
    "drugs_nonzero = drugs_df[drugs_df.givendose != 0] #drop all rows where givendose=0.0\n",
    "\n",
    "print(drugs_nonzero.shape)\n",
    "drugs_nonzero\n",
    "\n",
    "##1,313,057 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check datatypes in drugs_df table\n",
    "\n",
    "drugs_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if necessary - convert givenat to datetime format\n",
    "\n",
    "drugs_df['givenat'] =  pd.to_datetime(drugs_df['givenat'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "drugs_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show count of each drug field\n",
    "\n",
    "drugs_df['pharmaid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show all route values\n",
    "\n",
    "drugs_df['route'].unique()\n",
    "\n",
    "##only continuous administration - as required "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of unique ICU admissions\n",
    "##note: patientid corresponds to ICU admissions (not patient identifier)\n",
    "\n",
    "pat_drugs = list(drugs_df['patientid'].unique())\n",
    "len(pat_drugs)\n",
    "\n",
    "#10,665 unique ICU admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check number of unique instances (patientid + givenat)\n",
    "\n",
    "agg = drugs_df.groupby(['patientid','givenat'])['pharmaid'].nunique()\n",
    "agg = pd.DataFrame(data=agg, index=None)\n",
    "agg = agg.reset_index()\n",
    "print(agg.shape)\n",
    "agg.head(10)\n",
    "\n",
    "##1,430,607 unique instances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter for 15min time intervals (per patientid) containing (non-zero) readings for Adrenaline/Noradrenaline\n",
    "\n",
    "agg_drugs = drugs_nonzero.groupby([pd.Grouper(key='givenat', freq='15Min'), 'patientid']).pharmaid.unique()\n",
    "agg_drugs = pd.DataFrame(data=agg_drugs)\n",
    "agg_drugs = agg_drugs.reset_index()\n",
    "agg_drugs = agg_drugs.sort_values(by=['patientid','givenat'], ascending=[True,True])\n",
    "\n",
    "print(agg_drugs.shape)\n",
    "agg_drugs.head(15)\n",
    "\n",
    "#818,425 unique instances (with non-zero values for Adrenaline/Noradrenaline) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check datatypes - givenat should be in datetime format\n",
    "\n",
    "agg_drugs.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check unique ICU admissions\n",
    "\n",
    "agg_drugs['patientid'].nunique()\n",
    "\n",
    "##10,634 unique ICU admissions that have non-zero values for Adrenaline/Noradrenaline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Calculate drug rate for instances with Adrenaline/Noradrenaline drug readings (mg/hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Order drugs_df table by patientid, pharmaid, givenat\n",
    "\n",
    "drugs_df.sort_values(by=['patientid','pharmaid','givenat'])\n",
    "\n",
    "print(drugs_df.shape)\n",
    "drugs_df.head()\n",
    "\n",
    "##1,458,539 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm givenat is in datetime format\n",
    "\n",
    "drugs_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract relevant columns from drugs_df\n",
    "\n",
    "drugs_mod = drugs_df.copy(deep=True)\n",
    "drugs_mod = drugs_mod[['patientid', 'pharmaid', 'givenat', 'timepoint', 'givendose','cumulativedose','doseunit']]\n",
    "\n",
    "print(drugs_mod.shape)\n",
    "drugs_mod.head()\n",
    "\n",
    "##1,458,539 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check drug units\n",
    "\n",
    "drugs_mod['doseunit'].unique()\n",
    "\n",
    "##unit = micrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get min_time for each (patientid, pharmaid, timepoint)\n",
    "##min_time = minimum (earliest) drug administration time within given timepoint\n",
    "\n",
    "temp = drugs_mod.groupby(['patientid','pharmaid', 'timepoint'])\n",
    "min_time = temp.agg(min_time=('givenat', np.min))\n",
    "min_time = min_time.reset_index()\n",
    "min_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get cumulative dose for min_time per patientid in drugs_mod  \n",
    "\n",
    "merge = pd.merge(min_time, drugs_mod, left_on=['patientid','pharmaid','timepoint','min_time'], right_on=['patientid','pharmaid','timepoint','givenat'])\n",
    "min_cumval = merge[['patientid', 'pharmaid','timepoint','min_time','cumulativedose']]\n",
    "min_cumval.rename({'cumulativedose': 'cumulativedose(min)'}, axis=1, inplace=True)\n",
    "min_cumval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get max_time for each (patientid, pharmaid, timepoint)\n",
    "##max_time = maximum (latest) drug administration time within given timepoint\n",
    "\n",
    "temp = drugs_mod.groupby(['patientid','pharmaid','timepoint'])\n",
    "max_time = temp.agg(max_time=('givenat', np.max))\n",
    "max_time = max_time.reset_index()\n",
    "max_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get cumulative dose for max_time per patientid in drugs_mod  \n",
    "\n",
    "merge = pd.merge(max_time, drugs_mod, left_on=['patientid','pharmaid','timepoint','max_time'], right_on=['patientid','pharmaid','timepoint','givenat'])\n",
    "max_cumval = merge[['patientid', 'pharmaid','timepoint','max_time','cumulativedose']]\n",
    "max_cumval.rename({'cumulativedose': 'cumulativedose(max)'}, axis=1, inplace=True)\n",
    "max_cumval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate drugs rate\n",
    "\n",
    "drugs_rate = pd.merge(min_cumval, max_cumval, left_on=['patientid','pharmaid','timepoint'], right_on=['patientid','pharmaid','timepoint'])\n",
    "\n",
    "drugs_rate['time_diff'] = drugs_rate['max_time']-drugs_rate['min_time']\n",
    "drugs_rate['time_diff(mins)'] = (drugs_rate['time_diff'] / np.timedelta64(1, 'h'))*60\n",
    "drugs_rate['cumulativedose_diff'] = drugs_rate['cumulativedose(max)']-drugs_rate['cumulativedose(min)']\n",
    "\n",
    "drugs_rate['rate(microg/min)']= drugs_rate['cumulativedose_diff']/drugs_rate['time_diff(mins)']\n",
    "drugs_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Covert rate units from microgrames/min to milligrams/hr\n",
    "\n",
    "conversion = 0.060000071999942\n",
    "\n",
    "drugs_rate['rate(millig/hr)']=drugs_rate['rate(microg/min)']*conversion\n",
    "drugs_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter for acceptable rate values \n",
    "\n",
    "drugs_rate = drugs_rate[drugs_rate['rate(millig/hr)']<10]\n",
    "drugs_rate = drugs_rate[drugs_rate['rate(millig/hr)']>0]\n",
    "\n",
    "print(drugs_rate.shape)\n",
    "drugs_rate\n",
    "\n",
    "##272,932 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check min and max drug rate\n",
    "\n",
    "max_rate = drugs_rate['rate(millig/hr)'].max()\n",
    "min_rate = drugs_rate['rate(millig/hr)'].min()\n",
    "print(\"Lowest drug rate:\", min_rate)\n",
    "print(\"Highest drug rate:\", max_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename pharmaid to drug name \n",
    "\n",
    "drugs_rate['pharmaid'] = drugs_rate['pharmaid'].replace({ 1000649 : \"Adrenaline\", 1000650 : \"Adrenaline\", \n",
    "                                                         1000656: \"Noradrenaline\", 1000657 : \"Noradrenaline\"})\n",
    "drugs_rate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract relevant columns from drugs_rate\n",
    "\n",
    "drugs_rate = drugs_rate[['patientid','pharmaid','timepoint','rate(millig/hr)']]\n",
    "\n",
    "print(drugs_rate.shape)\n",
    "drugs_rate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reformat drugs_rate DF to structure similar to training data \n",
    "\n",
    "drugs_rate = drugs_rate.groupby(['patientid', 'timepoint', 'pharmaid'])['rate(millig/hr)'].sum().unstack('pharmaid')\n",
    "\n",
    "drugs_rate = drugs_rate.reset_index()\n",
    "drugs_rate = drugs_rate.rename_axis(None, axis=1)\n",
    "\n",
    "drugs_rate['Adrenaline'] = round(drugs_rate['Adrenaline'],2)\n",
    "drugs_rate['Noradrenaline'] = round(drugs_rate['Noradrenaline'],2)\n",
    "\n",
    "print(drugs_rate.shape)\n",
    "drugs_rate\n",
    "\n",
    "#268,461 records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Find instances with physiological parameter readings (FiO2/SpO2/HR/MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HiRID documentation contains the variableids for all physiological parameters:<br>\n",
    "https://hirid.intensivecare.ai/structure-of-the-published-data\n",
    "\n",
    "- **FiO2**: 2010\n",
    "- **SpO2**: 4000, 8280\n",
    "- **Heart Rate**: 200\n",
    "- **Mean Arterial Pressure**: 110, 610"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to observations_table_1\n",
    "\n",
    "obs_tab1 = pd.read_sql_query(\" SELECT * FROM hirid.observations_table_1 \\\n",
    "                                    WHERE variableid IN (200, 110, 610, 4000, 8280, 2010) \\\n",
    "                                    ORDER BY patientid, datetime \", conn)\n",
    "\n",
    "obs_tab1['row_idx']=obs_tab1.index #create new index column\n",
    "\n",
    "obs_tab1.to_csv('obs_tab1.csv')\n",
    "\n",
    "print(obs_tab1.shape)\n",
    "obs_tab1.head()\n",
    "\n",
    "#number of records = 19,492,758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to observations_table_2\n",
    "\n",
    "obs_tab2 = pd.read_sql_query(\" SELECT * FROM hirid.observations_table_2 \\\n",
    "                                    WHERE variableid IN (200, 110, 610, 4000, 8280, 2010) \\\n",
    "                                    ORDER BY patientid, datetime \", conn)\n",
    "\n",
    "obs_tab2['row_idx']=obs_tab2.index #create new index column\n",
    "\n",
    "obs_tab2.to_csv('obs_tab2.csv')\n",
    "\n",
    "print(obs_tab2.shape)\n",
    "obs_tab2.head()\n",
    "\n",
    "#number of records = 19,373,029"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to observations_table_3\n",
    "\n",
    "obs_tab3 = pd.read_sql_query(\" SELECT * FROM hirid.observations_table_3 \\\n",
    "                                    WHERE variableid IN (200, 110, 610, 4000, 8280, 2010) \\\n",
    "                                    ORDER BY patientid, datetime \", conn)\n",
    "\n",
    "obs_tab3['row_idx']=obs_tab3.index #create new index column\n",
    "\n",
    "obs_tab3.to_csv('obs_tab3.csv')\n",
    "\n",
    "print(obs_tab3.shape)\n",
    "obs_tab3.head()\n",
    "\n",
    "#number of records = 19,922,456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to observations_table_4\n",
    "\n",
    "obs_tab4 = pd.read_sql_query(\" SELECT * FROM hirid.observations_table_4 \\\n",
    "                                    WHERE variableid IN (200, 110, 610, 4000, 8280, 2010) \\\n",
    "                                    ORDER BY patientid, datetime \", conn)\n",
    "\n",
    "obs_tab4['row_idx']=obs_tab4.index #create new index column\n",
    "\n",
    "obs_tab4.to_csv('obs_tab4.csv')\n",
    "\n",
    "print(obs_tab4.shape)\n",
    "obs_tab4.head()\n",
    "\n",
    "#number of records = 19,576,004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to observations_table_5\n",
    "\n",
    "obs_tab5 = pd.read_sql_query(\" SELECT * FROM hirid.observations_table_5 \\\n",
    "                                    WHERE variableid IN (200, 110, 610, 4000, 8280, 2010) \\\n",
    "                                    ORDER BY patientid, datetime \", conn)\n",
    "\n",
    "obs_tab5['row_idx']=obs_tab5.index #create new index column\n",
    "\n",
    "obs_tab5.to_csv('obs_tab5.csv')\n",
    "\n",
    "print(obs_tab5.shape)\n",
    "obs_tab5.head()\n",
    "\n",
    "#number of records = 19,475,848"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to observations_table_6\n",
    "\n",
    "obs_tab6 = pd.read_sql_query(\" SELECT * FROM hirid.observations_table_6 \\\n",
    "                                    WHERE variableid IN (200, 110, 610, 4000, 8280, 2010) \\\n",
    "                                    ORDER BY patientid, datetime \", conn)\n",
    "\n",
    "obs_tab6['row_idx']=obs_tab6.index #create new index column\n",
    "\n",
    "obs_tab6.to_csv('obs_tab6.csv')\n",
    "\n",
    "print(obs_tab6.shape)\n",
    "obs_tab6.head()\n",
    "\n",
    "#number of records = 19,612,923"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to observations_table_7\n",
    "\n",
    "obs_tab7 = pd.read_sql_query(\" SELECT * FROM hirid.observations_table_7 \\\n",
    "                                    WHERE variableid IN (200, 110, 610, 4000, 8280, 2010) \\\n",
    "                                    ORDER BY patientid, datetime \", conn)\n",
    "\n",
    "obs_tab7['row_idx']=obs_tab7.index #create new index column\n",
    "\n",
    "obs_tab7.to_csv('obs_tab7.csv')\n",
    "\n",
    "print(obs_tab7.shape)\n",
    "obs_tab7.head()\n",
    "\n",
    "## number of records = 19,818,593"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to observations_table_8\n",
    "\n",
    "obs_tab8 = pd.read_sql_query(\" SELECT * FROM hirid.observations_table_8 \\\n",
    "                                    WHERE variableid IN (200, 110, 610, 4000, 8280, 2010) \\\n",
    "                                    ORDER BY patientid, datetime \", conn)\n",
    "\n",
    "obs_tab8['row_idx']=obs_tab8.index #create new index column\n",
    "\n",
    "obs_tab8.to_csv('obs_tab8.csv')\n",
    "\n",
    "print(obs_tab8.shape)\n",
    "obs_tab8.head()\n",
    "\n",
    "#number of records = 19,449,724"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to observations_table_9\n",
    "\n",
    "obs_tab9 = pd.read_sql_query(\" SELECT * FROM hirid.observations_table_9 \\\n",
    "                                    WHERE variableid IN (200, 110, 610, 4000, 8280, 2010) \\\n",
    "                                    ORDER BY patientid, datetime \", conn)\n",
    "\n",
    "obs_tab9['row_idx']=obs_tab9.index #create new index column\n",
    "\n",
    "obs_tab9.to_csv('obs_tab9.csv')\n",
    "\n",
    "print(obs_tab9.shape)\n",
    "obs_tab9.head()\n",
    "\n",
    "#number of records = 19,922,926"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to observations_table_10\n",
    "\n",
    "obs_tab10 = pd.read_sql_query(\" SELECT * FROM hirid.observations_table_10 \\\n",
    "                                    WHERE variableid IN (200, 110, 610, 4000, 8280, 2010) \\\n",
    "                                    ORDER BY patientid, datetime \", conn)\n",
    "\n",
    "obs_tab10['row_idx']=obs_tab10.index #create new index column\n",
    "\n",
    "obs_tab10.to_csv('obs_tab10.csv')\n",
    "\n",
    "print(obs_tab10.shape)\n",
    "obs_tab10.head()\n",
    "\n",
    "#number of records = 18,538,580"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of records observation_table_1:', len(obs_tab1))\n",
    "print('Number of records observation_table_2:', len(obs_tab2))\n",
    "print('Number of records observation_table_3:', len(obs_tab3))\n",
    "print('Number of records observation_table_4:', len(obs_tab4))\n",
    "print('Number of records observation_table_5:', len(obs_tab5))\n",
    "print('Number of records observation_table_6:', len(obs_tab6))\n",
    "print('Number of records observation_table_7:', len(obs_tab7))\n",
    "print('Number of records observation_table_8:', len(obs_tab8))\n",
    "print('Number of records observation_table_9:', len(obs_tab9))\n",
    "print('Number of records observation_table_10:', len(obs_tab10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate above observation tables datasets (1-10)\n",
    "\n",
    "frames = [obs_tab1, obs_tab2, obs_tab3, obs_tab4, obs_tab5, obs_tab6, obs_tab7, obs_tab8, obs_tab9, obs_tab10]\n",
    "\n",
    "phys_params = pd.concat(frames)\n",
    "\n",
    "phys_params['timepoint'] = phys_params['datetime'].dt.round('15min') #timepoint col needed in later manipulationn\n",
    "\n",
    "phys_params.to_csv('phys_params.csv')\n",
    "\n",
    "print(phys_params.shape)\n",
    "phys_params\n",
    "\n",
    "##195,182,841 records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Find instances with 15min intervals containing readings for all 4 physiological parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using phys_params\n",
    "#List unique physiological variableids within 15min time intervals, per patientid \n",
    "##datetime needs to be in correct format for query to run\n",
    "\n",
    "agg_var_full = phys_params.groupby([pd.Grouper(key='datetime', freq='15Min'), 'patientid']).variableid.unique()\n",
    "agg_var_full = pd.DataFrame(data=agg_var_full)\n",
    "agg_var_full = agg_var_full.reset_index()\n",
    "agg_var_full = agg_var_full.sort_values(by=['patientid','datetime'], ascending=[True,True])\n",
    "\n",
    "agg_var_full.to_csv('agg_var_full.csv')\n",
    "\n",
    "print(agg_var_full.shape)\n",
    "agg_var_full.head(5)\n",
    "\n",
    "##7,204,889 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter agg_var_full for all instances that contain a reading for FiO2\n",
    "\n",
    "#FiO2\n",
    "df_mod = agg_var_full[agg_var_full.variableid.astype(str).str.contains('2010')]\n",
    "print(df_mod.shape)\n",
    "df_mod\n",
    "\n",
    "##3,040,811 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter df_mod for all instances that contain a reading for SpO2\n",
    "\n",
    "df_mod = df_mod[df_mod.variableid.astype(str).str.contains('4000|8280')]\n",
    "print(df_mod.shape)\n",
    "df_mod\n",
    "\n",
    "##3,021,057 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter df_mod for all instances that contain a reading for HR\n",
    "\n",
    "df_mod = df_mod[df_mod.variableid.astype(str).str.contains('200')]\n",
    "print(df_mod.shape)\n",
    "df_mod\n",
    "\n",
    "##3,020,405"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter df_mod for all instances that contain a reading for MAP\n",
    "\n",
    "df_mod = df_mod[df_mod.variableid.astype(str).str.contains('110|610')]\n",
    "\n",
    "df_mod.to_csv('df_mod.csv')\n",
    "\n",
    "print(df_mod.shape)\n",
    "df_mod\n",
    "\n",
    "##3,004,013\n",
    "##There are 3,004,013 unique instances which contain readings for all 4 physiological parameters\n",
    "##This is our pool of relevant (patientid + timepoint) combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check unique ICU admissions\n",
    "\n",
    "df_mod['patientid'].nunique()\n",
    "\n",
    "##20,289 unique ICU admissions within above pool of relevant instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod.groupby(['datetime', 'patientid']).ngroups\n",
    "\n",
    "#confirms there are 3,004,013 unique combinations of (15min time interval + patientid) that have readings for 4 phys params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Find instances with readings for Adrenaline/Noradrenaline AND all 4 physiological parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge df_mod and agg_drugs\n",
    "##Pool of relevant instances (unique timepoint + patientid)\n",
    "\n",
    "agg_pool = pd.merge(df_mod, agg_drugs,  how='left', left_on=['datetime','patientid'], right_on = ['givenat','patientid'])\n",
    "agg_pool = agg_pool.drop(['givenat'],axis=1)\n",
    "agg_pool.rename({'datetime': 'timepoint'}, axis=1, inplace=True)\n",
    "\n",
    "agg_pool['timepoint'] =  pd.to_datetime(agg_pool['timepoint'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "agg_pool.to_csv('agg_pool.csv')\n",
    "\n",
    "print(agg_pool.shape)\n",
    "agg_pool\n",
    "\n",
    "#3,004,013 instances that have 4+ readings for phyiological parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if necessary - convert timepoint to datetime format\n",
    "agg_pool['timepoint'] =  pd.to_datetime(agg_pool['timepoint'], format='%Y-%m-%d %H:%M:%S')\n",
    "agg_pool.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check how many instances (unique patientid + timepoint) are common between df_mod and agg_drugs \n",
    "\n",
    "agg_merge = pd.merge(agg_drugs, df_mod,  how='left', left_on=['givenat','patientid'], right_on = ['datetime','patientid'])\n",
    "agg_merge = agg_merge.drop(['datetime'],axis=1)\n",
    "agg_merge.rename({'givenat': 'timepoint'}, axis=1, inplace=True)\n",
    "\n",
    "agg_merge = agg_merge[agg_merge['variableid'].notna()]\n",
    "\n",
    "print(agg_merge.shape)\n",
    "agg_merge.head()\n",
    "\n",
    "#610,917 instances with non-zero readings for Adrenaline/Noradrenaline AND all 4 physiological parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) For (patientid + timepoint) present in agg_pool, find all instances of physiological parameter readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter phys_params for only relevant (patientid + timepoint) combinations (ie. those present in agg_pool dataframe)\n",
    "\n",
    "params_mod = pd.merge(phys_params, agg_pool,  how='left', left_on=['timepoint','patientid'], right_on = ['timepoint','patientid'])\n",
    "\n",
    "params_mod = params_mod[params_mod['variableid_y'].notna()]\n",
    "\n",
    "params_mod.to_csv('params_mod.csv')\n",
    "\n",
    "print(params_mod.shape)\n",
    "params_mod.head()\n",
    "\n",
    "##91,507,817 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename variableid_x\n",
    "params_mod.rename({'variableid_x': 'variable'}, axis=1, inplace=True)\n",
    "params_mod.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract relevant cols from params_comp_mod\n",
    "\n",
    "params_comp = params_mod[['patientid','timepoint', 'variable', 'value']]\n",
    "\n",
    "params_comp = params_comp.sort_values(by=['patientid','timepoint','variable'], ascending=[True,True,True])\n",
    "\n",
    "print(params_comp.shape)\n",
    "params_comp.head()\n",
    "\n",
    "##91,507,817 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace variable numbers by names\n",
    "\n",
    "params_comp['variable'] = params_comp['variable'].replace({ 2010 : \"FiO2\", 4000 : \"SpO2\", 8280: \"SpO2\", 200 : \"HR\", \n",
    "                                                    110 : \"MAP\", 610 : \"MAP\"})\n",
    "print(params_comp.shape)\n",
    "params_comp.head()\n",
    "\n",
    "##91,507,817 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List all variables per unique (patientid + timepoint)\n",
    "##Primary Key = (patientid + timepoint + variable)\n",
    "\n",
    "params_comp = params_comp.groupby(['patientid','timepoint', 'variable'])['value'].apply(list)\n",
    "\n",
    "params_comp = pd.DataFrame(data=params_comp)\n",
    "params_comp = params_comp.reset_index()\n",
    "\n",
    "params_comp.to_csv('params_comp.csv')\n",
    "\n",
    "print(params_comp.shape)\n",
    "params_comp\n",
    "\n",
    "##11,955,825 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check unique ICU admissions in params_comp\n",
    "\n",
    "params_comp['patientid'].nunique()\n",
    "\n",
    "##20,286 unique ICU admissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Check all variable values are in acceptable range with compatible units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check format of 'value' column\n",
    "\n",
    "for i, l in enumerate(params_comp[\"value\"]):\n",
    "    print(\"list\",i,\"is\",type(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IF format = String: Change format of 'value'column from string to list (in order to loop through)\n",
    "##IF format = List: skip this step\n",
    "\n",
    "def clean_alt_list(list_):\n",
    "    list_ = list_.replace(', ', '\",\"')\n",
    "    list_ = list_.replace('[', '[\"')\n",
    "    list_ = list_.replace(']', '\"]')\n",
    "    return list_\n",
    "\n",
    "params_comp[\"value\"]= params_comp[\"value\"].apply(clean_alt_list)\n",
    "params_comp[\"value\"] = params_comp[\"value\"].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add row identifier column\n",
    "\n",
    "params_comp['row_idx']=params_comp.index \n",
    "print(params_comp.shape)\n",
    "params_comp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert value column to array - in order to loop through each list\n",
    "\n",
    "arr = params_comp.value.apply(lambda x: [float(c) for c in x])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert value column back to dataframe (and rename)\n",
    "\n",
    "arr_df = pd.DataFrame(data=arr,index=None)\n",
    "arr_df.columns = ['val_list']\n",
    "arr_df['row_idx']=arr_df.index #create new index column\n",
    "arr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge formatted val_list column with params_comp\n",
    "\n",
    "params_comp = pd.merge(params_comp, arr_df,  how='left', on=['row_idx'])\n",
    "params_comp = params_comp.drop(['row_idx','value'],axis=1)\n",
    "params_comp\n",
    "\n",
    "##11,955,825 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check all FiO2 values are in acceptable range\n",
    "\n",
    "check_fio2 = params_comp.copy(deep=True)\n",
    "\n",
    "check_fio2 = check_fio2[check_fio2['variable']=='FiO2']\n",
    "check_fio2['fio2_check'] = check_fio2.val_list.apply(lambda x: [ all(c >= 21 and c <=100 for c in x)])\n",
    "check_fio2['acceptable_range'] = check_fio2.fio2_check.apply(lambda x: 'Yes' if True in x else 'No')\n",
    "\n",
    "check_fio2\n",
    "\n",
    "##2,983,684 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(check_fio2[check_fio2['acceptable_range']=='No'])\n",
    "\n",
    "#2,439 instances containing FiO2 values outside acceptable range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new column FiO2 values that are in acceptable range\n",
    "\n",
    "check_fio2['inrange_val_list'] = check_fio2.val_list.apply(lambda x: [ c for c in x if 21 <= c <= 100])\n",
    "check_fio2 = check_fio2.drop(['val_list','fio2_check','acceptable_range'],axis=1)\n",
    "\n",
    "check_fio2 = check_fio2.dropna()\n",
    "\n",
    "print(check_fio2.shape)\n",
    "check_fio2.head()\n",
    "\n",
    "##2,983,684 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm all FiO2 values are in acceptable range\n",
    "\n",
    "check_fio2['fio2_check'] = check_fio2.inrange_val_list.apply(lambda x: [ all(c >= 21 and c <=100 for c in x)])\n",
    "check_fio2['acceptable_range'] = check_fio2.fio2_check.apply(lambda x: 'Yes' if True in x else 'No')\n",
    "\n",
    "check_fio2['acceptable_range'].unique()\n",
    "\n",
    "##All FiO2 values are now in acceptable range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unncessary columns\n",
    "\n",
    "check_fio2 = check_fio2.drop(['fio2_check','acceptable_range'],axis=1)\n",
    "print(check_fio2.shape)\n",
    "check_fio2.head()\n",
    "\n",
    "##2,983,684 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check all SpO2 values are in acceptable range\n",
    "\n",
    "check_spo2 = params_comp.copy(deep=True)\n",
    "\n",
    "check_spo2 = check_spo2[check_spo2['variable']=='SpO2']\n",
    "check_spo2['spo2_check'] = check_spo2.val_list.apply(lambda x: [ all(c >= 0 and c <=100 for c in x)])\n",
    "check_spo2['acceptable_range'] = check_spo2.spo2_check.apply(lambda x: 'Yes' if True in x else 'No')\n",
    "\n",
    "check_spo2\n",
    "\n",
    "##2,988,937 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(check_spo2[check_spo2['acceptable_range']=='No'])\n",
    "\n",
    "#14 instances contain SpO2 values outside acceptable ranges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new column SpO2 values that are in acceptable range\n",
    "\n",
    "check_spo2['inrange_val_list'] = check_spo2.val_list.apply(lambda x: [ c for c in x if 0 <= c <= 100])\n",
    "check_spo2 = check_spo2.drop(['val_list','spo2_check','acceptable_range'],axis=1)\n",
    "\n",
    "check_spo2 = check_spo2.dropna()\n",
    "\n",
    "print(check_spo2.shape)\n",
    "check_spo2.head()\n",
    "\n",
    "##2,988,937 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm all SpO2 values are in acceptable range\n",
    "\n",
    "check_spo2['spo2_check'] = check_spo2.inrange_val_list.apply(lambda x: [ all(c >= 0 and c <=100 for c in x)])\n",
    "check_spo2['acceptable_range'] = check_spo2.spo2_check.apply(lambda x: 'Yes' if True in x else 'No')\n",
    "\n",
    "check_spo2['acceptable_range'].unique()\n",
    "\n",
    "##All SpO2 values are now in acceptable range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unncessary columns\n",
    "\n",
    "check_spo2 = check_spo2.drop(['spo2_check','acceptable_range'],axis=1)\n",
    "print(check_spo2.shape)\n",
    "check_spo2.head()\n",
    "\n",
    "##2,988,937 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check all MAP values are in acceptable range\n",
    "\n",
    "check_map = params_comp.copy(deep=True)\n",
    "\n",
    "check_map = check_map[check_map['variable']=='MAP']\n",
    "check_map['map_check'] = check_map.val_list.apply(lambda x: [ all(c >= 0 and c <=200 for c in x)])\n",
    "check_map['acceptable_range'] = check_map.map_check.apply(lambda x: 'Yes' if True in x else 'No')\n",
    "\n",
    "check_map\n",
    "\n",
    "##2,989,610 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(check_map[check_map['acceptable_range']=='No'])\n",
    "\n",
    "#61,820 instances contain an MAP reading outside the acceptable range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new column MAP values that are in acceptable range\n",
    "\n",
    "check_map['inrange_val_list'] = check_map.val_list.apply(lambda x: [ c for c in x if 0 <= c <= 200])\n",
    "check_map = check_map.drop(['val_list','map_check','acceptable_range'],axis=1)\n",
    "\n",
    "check_map = check_map.dropna()\n",
    "\n",
    "print(check_map.shape)\n",
    "check_map.head()\n",
    "\n",
    "##2,989,610 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm all MAP values are in acceptable range\n",
    "\n",
    "check_map['map_check'] = check_map.inrange_val_list.apply(lambda x: [ all(c >= 0 and c <=200 for c in x)])\n",
    "check_map['acceptable_range'] = check_map.map_check.apply(lambda x: 'Yes' if True in x else 'No')\n",
    "\n",
    "check_map['acceptable_range'].unique()\n",
    "\n",
    "##All MAP values are now in acceptable range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unncessary columns\n",
    "\n",
    "check_map = check_map.drop(['map_check','acceptable_range'],axis=1)\n",
    "print(check_map.shape)\n",
    "check_map.head()\n",
    "\n",
    "##2,989,610 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check all HR values are in acceptable range\n",
    "\n",
    "check_hr = params_comp.copy(deep=True)\n",
    "\n",
    "check_hr = check_hr[check_hr['variable']=='HR']\n",
    "check_hr['hr_check'] = check_hr.val_list.apply(lambda x: [ all(c >= 0 and c <=300 for c in x)])\n",
    "check_hr['acceptable_range'] = check_hr.hr_check.apply(lambda x: 'Yes' if True in x else 'No')\n",
    "check_hr\n",
    "\n",
    "##2,993,594 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(check_hr[check_hr['acceptable_range']=='No'])\n",
    "\n",
    "#All HR values are in acceptable range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unncessary columns\n",
    "\n",
    "check_hr = check_hr.drop(['hr_check','acceptable_range'],axis=1)\n",
    "check_hr.rename({'val_list': 'inrange_val_list'}, axis=1, inplace=True)\n",
    "\n",
    "print(check_hr.shape)\n",
    "check_hr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(check_fio2.columns)\n",
    "print(check_spo2.columns)\n",
    "print(check_map.columns)\n",
    "print(check_hr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate check,fio2, check_spo2, check_map check_hr\n",
    "\n",
    "frames = [check_fio2, check_spo2, check_map, check_hr]\n",
    "\n",
    "params_comp = pd.concat(frames)\n",
    "\n",
    "params_comp.sort_values(by=['patientid','timepoint'], ascending=[True,True])\n",
    "\n",
    "print(params_comp.shape)\n",
    "params_comp\n",
    "\n",
    "##11,955,825 records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8)  Extract minimum, maximum and average variable values per unique instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract minimum and maximum variable values\n",
    "\n",
    "params_comp['min_val'] = params_comp.inrange_val_list.apply(lambda x: min(x, default=np.nan))\n",
    "params_comp['max_val'] = params_comp.inrange_val_list.apply(lambda x: max(x, default=np.nan))\n",
    "\n",
    "print(params_comp.shape)\n",
    "params_comp.head()\n",
    "\n",
    "##11,955,825 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract average variable value\n",
    "\n",
    "import statistics\n",
    "\n",
    "params_comp = params_comp.dropna() #drop all rows containing null values (indicates empty value list)\n",
    "\n",
    "params_comp['avg_val'] = params_comp.inrange_val_list.apply(lambda x: round(statistics.mean(x),1))\n",
    "\n",
    "print(params_comp.shape)\n",
    "params_comp.head()\n",
    "\n",
    "##11,955,670 records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Remove instances where % variation is larger than defined cut-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As advised by our medical advisor, Prof Malcolm Sim, a large variation should not be observed within a such a short time period, and is indicative of a data error. <br>\n",
    "•\t**% variation** = (( max_val – min_val ) / min_val ) x 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check % variation of variable readings for each instance\n",
    "\n",
    "params_comp['variation(%)'] = ((params_comp['max_val']-params_comp['min_val'])/params_comp['min_val'])*100\n",
    "\n",
    "print(params_comp.shape)\n",
    "params_comp.head() \n",
    "\n",
    "##11,955,670 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove instances where the % variation of values within each 15-minute timepoint is within is greater than defined cut-off\n",
    "###Instances to remove - cut-offs advised by X (medical advisor to project)\n",
    "\n",
    "params_comp = params_comp[((params_comp['variable']=='FiO2') & (params_comp['variation(%)']<=5))|\n",
    "                          ((params_comp['variable']=='SpO2') & (params_comp['variation(%)']<=10))|\n",
    "                          ((params_comp['variable']=='MAP') & (params_comp['variation(%)']<=25))|\n",
    "                          ((params_comp['variable']=='HR') & (params_comp['variation(%)']<=25))]\n",
    "\n",
    "print(params_comp.shape)\n",
    "params_comp.head() \n",
    "\n",
    "#10,719,315 records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10) Check average parameter values match training data units and ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract relevant columns from params_comp\n",
    "##Reformat dataframe to similar structure as Glasgow training data, using average parameter values \n",
    "\n",
    "avg_params = params_comp[['patientid','timepoint','variable','avg_val']]\n",
    "\n",
    "avg_params = avg_params.groupby(['patientid', 'timepoint', 'variable'])['avg_val'].sum().unstack('variable')\n",
    "\n",
    "avg_params = avg_params.reset_index()\n",
    "avg_params = avg_params.rename_axis(None, axis=1)\n",
    "avg_params = avg_params.dropna() #drop any rows that contain null values \n",
    "\n",
    "print(avg_params.shape)\n",
    "avg_params\n",
    "\n",
    "##2,022,310 records\n",
    "##need to convert FiO2 units from % to decFrc (HR, MAP, SpO2 have correct units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert FiO2 to decFrc (compatible with Glasgow training data)\n",
    "\n",
    "avg_params['FiO2']=round((avg_params['FiO2']/100),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Confirm all average values are within acceptable range\n",
    "\n",
    "avg_params = avg_params[avg_params['FiO2']>=0.21]\n",
    "avg_params = avg_params[avg_params['FiO2']<=1.0]\n",
    "\n",
    "avg_params = avg_params[avg_params['SpO2']>0]\n",
    "avg_params = avg_params[avg_params['SpO2']<=100]\n",
    "\n",
    "avg_params = avg_params[avg_params['HR']>0]\n",
    "avg_params = avg_params[avg_params['HR']<=300]\n",
    "\n",
    "avg_params = avg_params[avg_params['MAP']>0]\n",
    "avg_params = avg_params[avg_params['MAP']<=200]\n",
    "\n",
    "print(avg_params.shape)\n",
    "avg_params\n",
    "\n",
    "##2,022,310 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check number of unique ICU admissions in avg_params\n",
    "\n",
    "avg_params['patientid'].nunique()\n",
    "\n",
    "##20,073 unique ICU admissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11) Create HiRID external dataset using Average parameter values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_params.shape)\n",
    "avg_params.head()\n",
    "\n",
    "##2,022,310 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_rate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if necessary - convert timepoint to correct datetime format\n",
    "drugs_rate['timepoint'] =  pd.to_datetime(drugs_rate['timepoint'], format='%Y-%m-%d %H:%M:%S')\n",
    "drugs_rate.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge avg_params and drugs_rate on (patientid + timepoint)\n",
    "\n",
    "comp_avg_params = pd.merge(avg_params, drugs_rate, how='left', on=['patientid','timepoint'])\n",
    "comp_avg_params = comp_avg_params[['patientid','timepoint','Adrenaline','Noradrenaline','FiO2','SpO2','MAP','HR']]\n",
    "\n",
    "comp_avg_params['rowID']=comp_avg_params.index #create new index column\n",
    "\n",
    "#move index col to start\n",
    "col_at_start = ['rowID']\n",
    "comp_avg_params = comp_avg_params[[c for c in col_at_start if c in comp_avg_params] + [c for c in comp_avg_params if c not in col_at_start]]\n",
    "\n",
    "#replace null with 0 in drug fields (as blank value indicates value=0)\n",
    "comp_avg_params['Adrenaline'] = comp_avg_params['Adrenaline'].replace(np.nan, 0)\n",
    "comp_avg_params['Noradrenaline'] = comp_avg_params['Noradrenaline'].replace(np.nan, 0)\n",
    "\n",
    "print(comp_avg_params.shape)\n",
    "comp_avg_params\n",
    "\n",
    "##2,022,310 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check number of non-zero drug fields\n",
    "\n",
    "print(len(comp_avg_params[comp_avg_params['Adrenaline']>0]))\n",
    "print(len(comp_avg_params[comp_avg_params['Noradrenaline']>0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12) Find discharge & death times for each unique ICU admission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the HiRID databse does not contain data for an ICU discharge/death time, the last Heart Rate reading was used as the discharge time (if discharge_status=alive) or death time (if discharge_status=dead). This approach was recommended by the HiRID v1.1.1 database corresponding author, Martin Faltys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to observations_table_1 - find all HR readings\n",
    "\n",
    "hr_tab1 = pd.read_sql_query(\" SELECT * FROM hirid.observations_table_1 \\\n",
    "                                    WHERE variableid IN (200) \\\n",
    "                                    ORDER BY patientid, datetime \", conn)\n",
    "\n",
    "hr_tab1['row_idx']=hr_tab1.index #create new index column\n",
    "\n",
    "print(hr_tab1.shape)\n",
    "hr_tab1.head()\n",
    "\n",
    "##6,076,840 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_tab1_patlist = list(hr_tab1['patientid'].unique())\n",
    "len(hr_tab1_patlist)\n",
    "\n",
    "##3386 unique admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find date of latest Heart Rate for each patientid in hr_tab1 -> this is equivalent to discharge/death time \n",
    "\n",
    "temp = hr_tab1.groupby('patientid')\n",
    "dtime_tab1 = temp.agg(max_date=('datetime', np.max))\n",
    "dtime_tab1 = dtime_tab1.reset_index()\n",
    "dtime_tab1\n",
    "\n",
    "#max_date = discharge time/ death time for all patientids in hr_tab1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to observations_table_2 - find all HR readings\n",
    "\n",
    "hr_tab2 = pd.read_sql_query(\" SELECT * FROM hirid.observations_table_2 \\\n",
    "                                    WHERE variableid IN (200) \\\n",
    "                                    ORDER BY patientid, datetime \", conn)\n",
    "\n",
    "hr_tab2['row_idx']=hr_tab2.index #create new index column\n",
    "\n",
    "print(hr_tab2.shape)\n",
    "hr_tab2.head()\n",
    "\n",
    "##5,943,365 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_tab2_patlist = list(hr_tab2['patientid'].unique())\n",
    "len(hr_tab2_patlist)\n",
    "\n",
    "##3391 unique admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find date of latest Heart Rate for each patientid in hr_tab2\n",
    "\n",
    "temp = hr_tab2.groupby('patientid')\n",
    "dtime_tab2 = temp.agg(max_date=('datetime', np.max))\n",
    "dtime_tab2 = dtime_tab2.reset_index()\n",
    "dtime_tab2\n",
    "\n",
    "#max_date = discharge time/ death time for all patientids in hr_tab2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to observations_table_3 - find all HR readings\n",
    "\n",
    "hr_tab3 = pd.read_sql_query(\" SELECT * FROM hirid.observations_table_3 \\\n",
    "                                    WHERE variableid IN (200) \\\n",
    "                                    ORDER BY patientid, datetime \", conn)\n",
    "\n",
    "hr_tab3['row_idx']=hr_tab3.index #create new index column\n",
    "\n",
    "print(hr_tab3.shape)\n",
    "hr_tab3.head()\n",
    "\n",
    "##6,157,038 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_tab3_patlist = list(hr_tab3['patientid'].unique())\n",
    "len(hr_tab3_patlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find date of latest Heart Rate for each patientid in hr_tab3\n",
    "\n",
    "temp = hr_tab3.groupby('patientid')\n",
    "dtime_tab3 = temp.agg(max_date=('datetime', np.max))\n",
    "dtime_tab3 = dtime_tab3.reset_index()\n",
    "dtime_tab3\n",
    "\n",
    "#max_date = discharge time/ death time for all patientids in hr_tab3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to observations_table_4 - find all HR readings\n",
    "\n",
    "hr_tab4 = pd.read_sql_query(\" SELECT * FROM hirid.observations_table_4 \\\n",
    "                                    WHERE variableid IN (200) \\\n",
    "                                    ORDER BY patientid, datetime \", conn)\n",
    "\n",
    "hr_tab4['row_idx']=hr_tab4.index #create new index column\n",
    "\n",
    "print(hr_tab4.shape)\n",
    "hr_tab4.head()\n",
    "\n",
    "##6,072,003 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_tab4_patlist = list(hr_tab4['patientid'].unique())\n",
    "len(hr_tab4_patlist)\n",
    "\n",
    "##3391 unique admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find date of latest Heart Rate for each patientid in hr_tab4\n",
    "\n",
    "temp = hr_tab4.groupby('patientid')\n",
    "dtime_tab4 = temp.agg(max_date=('datetime', np.max))\n",
    "dtime_tab4 = dtime_tab4.reset_index()\n",
    "dtime_tab4\n",
    "\n",
    "#max_date = discharge time/ death time for all patientids in hr_tab4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to observations_table_5 - find all HR readings\n",
    "\n",
    "hr_tab5 = pd.read_sql_query(\" SELECT * FROM hirid.observations_table_5 \\\n",
    "                                    WHERE variableid IN (200) \\\n",
    "                                    ORDER BY patientid, datetime \", conn)\n",
    "\n",
    "hr_tab5['row_idx']=hr_tab5.index #create new index column\n",
    "\n",
    "print(hr_tab5.shape)\n",
    "hr_tab5.head()\n",
    "\n",
    "##6,059,325 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_tab5_patlist = list(hr_tab5['patientid'].unique())\n",
    "len(hr_tab5_patlist)\n",
    "\n",
    "##3388 unique admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find date of latest Heart Rate for each patientid in hr_tab5\n",
    "\n",
    "temp = hr_tab5.groupby('patientid')\n",
    "dtime_tab5 = temp.agg(max_date=('datetime', np.max))\n",
    "dtime_tab5 = dtime_tab5.reset_index()\n",
    "dtime_tab5\n",
    "\n",
    "#max_date = discharge time/ death time for all patientids in hr_tab5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to observations_table_6 - find all HR readings\n",
    "\n",
    "hr_tab6 = pd.read_sql_query(\" SELECT * FROM hirid.observations_table_6 \\\n",
    "                                    WHERE variableid IN (200) \\\n",
    "                                    ORDER BY patientid, datetime \", conn)\n",
    "\n",
    "hr_tab6['row_idx']=hr_tab6.index #create new index column\n",
    "\n",
    "print(hr_tab6.shape)\n",
    "hr_tab6.head()\n",
    "\n",
    "##6,098,969 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_tab6_patlist = list(hr_tab6['patientid'].unique())\n",
    "len(hr_tab6_patlist)\n",
    "\n",
    "##3391 unique admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find date of latest Heart Rate for each patientid in hr_tab6\n",
    "\n",
    "temp = hr_tab6.groupby('patientid')\n",
    "dtime_tab6 = temp.agg(max_date=('datetime', np.max))\n",
    "dtime_tab6 = dtime_tab6.reset_index()\n",
    "dtime_tab6\n",
    "\n",
    "#max_date = discharge time/ death time for all patientids in hr_tab6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to observations_table_7 - find all HR readings\n",
    "\n",
    "hr_tab7 = pd.read_sql_query(\" SELECT * FROM hirid.observations_table_7 \\\n",
    "                                    WHERE variableid IN (200) \\\n",
    "                                    ORDER BY patientid, datetime \", conn)\n",
    "\n",
    "hr_tab7['row_idx']=hr_tab7.index #create new index column\n",
    "\n",
    "print(hr_tab7.shape)\n",
    "hr_tab7.head()\n",
    "\n",
    "##6,126,086 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_tab7_patlist = list(hr_tab7['patientid'].unique())\n",
    "len(hr_tab7_patlist)\n",
    "\n",
    "##3390 unique admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find date of latest Heart Rate for each patientid in hr_tab7\n",
    "\n",
    "temp = hr_tab7.groupby('patientid')\n",
    "dtime_tab7 = temp.agg(max_date=('datetime', np.max))\n",
    "dtime_tab7 = dtime_tab7.reset_index()\n",
    "dtime_tab7\n",
    "\n",
    "#max_date = discharge time/ death time for all patientids in hr_tab7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to observations_table_8 - find all HR readings \n",
    "\n",
    "hr_tab8 = pd.read_sql_query(\" SELECT * FROM hirid.observations_table_8 \\\n",
    "                                    WHERE variableid IN (200) \\\n",
    "                                    ORDER BY patientid, datetime \", conn)\n",
    "\n",
    "hr_tab8['row_idx']=hr_tab8.index #create new index column\n",
    "\n",
    "print(hr_tab8.shape)\n",
    "hr_tab8.head()\n",
    "\n",
    "##5,964,420 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_tab8_patlist = list(hr_tab8['patientid'].unique())\n",
    "len(hr_tab8_patlist)\n",
    "\n",
    "##3389 unique admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find date of latest Heart Rate for each patientid in hr_tab8\n",
    "\n",
    "temp = hr_tab8.groupby('patientid')\n",
    "dtime_tab8 = temp.agg(max_date=('datetime', np.max))\n",
    "dtime_tab8 = dtime_tab8.reset_index()\n",
    "dtime_tab8\n",
    "\n",
    "#max_date = discharge time/ death time for all patientids in hr_tab8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to observations_table_9 - find all HR readings\n",
    "\n",
    "hr_tab9 = pd.read_sql_query(\" SELECT * FROM hirid.observations_table_9 \\\n",
    "                                    WHERE variableid IN (200) \\\n",
    "                                    ORDER BY patientid, datetime \", conn)\n",
    "\n",
    "hr_tab9['row_idx']=hr_tab9.index #create new index column\n",
    "\n",
    "print(hr_tab9.shape)\n",
    "hr_tab9.head()\n",
    "\n",
    "##6,163,893 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_tab9_patlist = list(hr_tab9['patientid'].unique())\n",
    "len(hr_tab9_patlist)\n",
    "\n",
    "##3389 unique admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find date of latest Heart Rate for each patientid in hr_tab9\n",
    "\n",
    "temp = hr_tab9.groupby('patientid')\n",
    "dtime_tab9 = temp.agg(max_date=('datetime', np.max))\n",
    "dtime_tab9 = dtime_tab9.reset_index()\n",
    "dtime_tab9\n",
    "\n",
    "#max_date = discharge time/ death time for all patientids in hr_tab9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to observations_table_10 - find all HR readings\n",
    "\n",
    "hr_tab10 = pd.read_sql_query(\" SELECT * FROM hirid.observations_table_10 \\\n",
    "                                    WHERE variableid IN (200) \\\n",
    "                                    ORDER BY patientid, datetime \", conn)\n",
    "\n",
    "hr_tab10['row_idx']=hr_tab10.index #create new index column\n",
    "\n",
    "print(hr_tab10.shape)\n",
    "hr_tab10.head()\n",
    "\n",
    "##5,770,397 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_tab10_patlist = list(hr_tab10['patientid'].unique())\n",
    "len(hr_tab10_patlist)\n",
    "\n",
    "##3392 unique admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find date of latest Heart Rate for each patientid in hr_tab10\n",
    "\n",
    "temp = hr_tab10.groupby('patientid')\n",
    "dtime_tab10 = temp.agg(max_date=('datetime', np.max))\n",
    "dtime_tab10 = dtime_tab10.reset_index()\n",
    "dtime_tab10\n",
    "\n",
    "#max_date = discharge time/ death time for all patientids in hr_tab10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm no overlapping patientids across the 10 observations tables\n",
    "\n",
    "pat_in_all = list(set.intersection(*map(set, [hr_tab1_patlist, hr_tab2_patlist, hr_tab3_patlist, hr_tab4_patlist, hr_tab5_patlist, hr_tab6_patlist,hr_tab7_patlist, hr_tab8_patlist, hr_tab9_patlist, hr_tab10_patlist ])))\n",
    "pat_in_all\n",
    "\n",
    "#no overlapping patientids across hr_tab1, ht_tab2, hr_tab3, hr_tab4, ht_tab5, hr_tab6, hr_tab7, ht_tab8, hr_tab9 and hr_tab10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge above dtime tables to create table of discharge/death times per patientid \n",
    "\n",
    "frames = [dtime_tab1, dtime_tab2, dtime_tab3, dtime_tab4, dtime_tab5,\n",
    "         dtime_tab6, dtime_tab7, dtime_tab8, dtime_tab9, dtime_tab10]\n",
    "\n",
    "dtimes = pd.concat(frames)\n",
    "\n",
    "dtimes.sort_values(['patientid'], ascending=[True], inplace=True)\n",
    "\n",
    "print(dtimes.shape)\n",
    "dtimes\n",
    "\n",
    "##33,897 unique patientids (ICU admissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to HiRID pharma_records table\n",
    "\n",
    "pat = pd.read_sql_query(\"SELECT * FROM hirid.patient \\\n",
    "                         ORDER BY patientid\", conn)\n",
    "\n",
    "print(pat.shape)\n",
    "pat.head()\n",
    "\n",
    "##33,905 unique ICU admissions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check unique ICU admissions in 'General' table\n",
    "\n",
    "pat['patientid'].nunique()\n",
    "\n",
    "##33,905 unique ICU admissions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge dtimes with general_table \n",
    "\n",
    "pat_info = pd.merge(pat, dtimes,  how='left', left_on=['patientid'], right_on = ['patientid'])\n",
    "pat_info.rename({'max_date': 'd_time'}, axis=1, inplace=True)\n",
    "\n",
    "print(pat_info.shape)\n",
    "pat_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create ICU LOS column\n",
    "\n",
    "pat_info['icu_los'] = pat_info['d_time'] - pat_info['admissiontime']\n",
    "\n",
    "#convert to hours\n",
    "pat_info['icu_los'] = (pat_info['icu_los'] / np.timedelta64(1, 'h'))\n",
    "pat_info.rename({'icu_los': 'icu_los(hrs)'}, axis=1, inplace=True)\n",
    "\n",
    "print(pat_info.shape)\n",
    "pat_info.head()\n",
    "\n",
    "#33,905 records "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create fields for last hours before discharge/death (1hr/2hrs/3hrs/4hrs/7hrs/8hrs)\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "pat_info['1hr before d_time'] = pd.to_datetime(pat_info['d_time'])- timedelta(hours=1)\n",
    "pat_info['2hrs before d_time'] = pd.to_datetime(pat_info['d_time'])- timedelta(hours=2)\n",
    "pat_info['3hrs before d_time'] = pd.to_datetime(pat_info['d_time'])- timedelta(hours=3)\n",
    "pat_info['4hrs before d_time'] = pd.to_datetime(pat_info['d_time'])- timedelta(hours=4)\n",
    "pat_info['7hrs before d_time'] = pd.to_datetime(pat_info['d_time'])- timedelta(hours=7)\n",
    "pat_info['8hrs before d_time'] = pd.to_datetime(pat_info['d_time'])- timedelta(hours=8)\n",
    "\n",
    "print(pat_info.shape)\n",
    "pat_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13) Explore patient characteristics of final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(comp_avg_params.shape)\n",
    "comp_avg_params\n",
    "\n",
    "##2,022,310 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract patientids within comp_avg_params\n",
    "\n",
    "pat_rel = comp_avg_params['patientid'].unique()\n",
    "pat_rel = pd.DataFrame(data=pat_rel)\n",
    "pat_rel.columns = ['patientid']\n",
    "\n",
    "print(pat_rel.shape)\n",
    "pat_rel\n",
    "\n",
    "#20,073 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pat_info.shape)\n",
    "pat_info\n",
    "\n",
    "##33,905 unique ICU admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge pat_rel and pat_info\n",
    "\n",
    "df_patmerge = pd.merge(pat_rel, pat_info, how='left', left_on=['patientid'], right_on=['patientid'])\n",
    "print(df_patmerge.shape)\n",
    "df_patmerge.head()\n",
    "\n",
    "##20,073 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patmerge.describe()\n",
    "\n",
    "##mean age=64.3\n",
    "##mean ICU LOS = 69.1 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patmerge['sex'].value_counts()\n",
    "\n",
    "##13,659 males\n",
    "##6414 females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patmerge['discharge_status'].value_counts()\n",
    "\n",
    "##17,919 discharged alive\n",
    "##1,951 discharged dead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check how many of the 33,905 unique ICU admissions were adminsitered Adrenaline/Noradrenaline\n",
    "\n",
    "pat_all = list(pat['patientid'].unique())\n",
    "\n",
    "len(list(set(pat_all).intersection(pat_drugs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14) Create HiRID External Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define 1hr before discharge/death time period\n",
    "\n",
    "dtime_pre1hr = pat_info.copy(deep=True)\n",
    "dtime_pre1hr = dtime_pre1hr[['patientid', 'd_time', '1hr before d_time']]\n",
    "\n",
    "print(dtime_pre1hr.shape)\n",
    "dtime_pre1hr\n",
    "\n",
    "##33,905 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter for only instances with readings in the last hour before discharge/death\n",
    "\n",
    "params_1hr = pd.merge(comp_avg_params, dtime_pre1hr, how='left', left_on=['patientid'], right_on = ['patientid'])\n",
    "params_1hr = params_1hr[(params_1hr['timepoint']<params_1hr['d_time']) & (params_1hr['timepoint']>params_1hr['1hr before d_time'])]\n",
    "\n",
    "params_1hr.to_csv(\"params1hr.csv\")\n",
    "\n",
    "print(params_1hr.shape)\n",
    "params_1hr\n",
    "\n",
    "##3117 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import HiRID 'General' table (contains discharge_status info)\n",
    "#General table (& other HiRID tables) are found here: https://www.physionet.org/content/hirid/1.1.1/\n",
    "\n",
    "pat = pd.read_csv(\"./general_table.csv\")\n",
    "print(pat.shape)\n",
    "pat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add discharge status columns to params1hr dataframe\n",
    "\n",
    "params1hr['Time before dis/death(hrs)'] = 1\n",
    "params1hr = pd.merge(params1hr, pat, how='left', left_on=['patientid'], right_on = ['patientid'])\n",
    "\n",
    "print(params1hr.shape)\n",
    "params1hr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all rows containing null values\n",
    "\n",
    "params1hr = params1hr.dropna()\n",
    "\n",
    "print(params1hr.shape)\n",
    "params1hr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Final HiRID External Validation Dataset (balanecd on discharge status classes)\n",
    "\n",
    "sub_zero = test_zero.sample(n=1300, random_state=1)\n",
    "sub_one = test_one.sample(n=1300, random_state=1)\n",
    "\n",
    "frames = [sub_zero, sub_one]\n",
    "\n",
    "t_params1hr = pd.concat(frames)\n",
    "\n",
    "t_params1hr = t_params1hr.sort_values(by='rowID', ascending=True)\n",
    "t_params1hr = t_params1hr.reset_index()\n",
    "t_params1hr = t_params1hr.drop('index', axis=1)\n",
    "\n",
    "t_params1hr.to_csv('HiRID_extval_params1hr.csv')\n",
    "\n",
    "print(t_params1hr.shape)\n",
    "t_params1hr\n",
    "\n",
    "##t_params1hr = Hirid external validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check class balance of HiRID External Validation Dataset\n",
    "\n",
    "t_params1hr['binary_status'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
